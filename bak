# RUN pip install -r requirements.txt
RUN CMAKE_ARGS="-LLAMA_CUDA=on" pip install llama-cpp-python

langchain
chromadb
gigachat

RUN pip install -r requirements.txt

RUN conda create --name llama-env python=3.12
RUN conda activate llama-env


COPY Meta-Llama-3-8B-Instruct.Q4_1.gguf /app

COPY llama3.py /app

RUN pip install -c "nvidia/label/cuda-11.8.0" cuda-toolkit cuda-nvcc -y --copy
RUN CMAKE_ARGS="-LLAMA_CUDA=on" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

ENTRYPOINT [ "streamlit", "run"]
CMD ["federallab.py"]